---
pagetitle: "Data Literacy"
format: 
  revealjs:
    chalkboard: true
    incremental: true
    theme: [default, custom.scss]
    multiplex: true
    height: 900
    width: 1600
    slide-number: c
    auto-stretch: false
    callout-appearance: simple
    pdf-max-pages-per-slide: 2
    menu: 
      side: right
      numbers: true
execute:
  echo: true
  warning: false
  message: false
---

```{r}
#| include: false
#| warning: false
#| message: false

knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      fig.retina = 3, fig.align = 'center')
library(knitr)
library(tidyverse)

# set width of code output
# options(width = 65)
```

::::: columns
::: {.column .center width="60%"}
![](img/DAW.png){width="90%"}
:::

::: {.column .center width="40%"}
<br>

[Data Literacy]{.custom-title}

<br> <br> <br> <br>

[Kelly McConville]{.custom-subtitle}

[Coffee and Treats with L&IT \| Fall 2024]{.custom-subtitle}
:::
:::::

# Data literacy: The ability to **read**, **evaluate**, and **construct** arguments with data.

------------------------------------------------------------------------

## Bombardment of Data Arguments

::::: columns
::: {.column .center width="50%"}
![NYTimes "What's Going on in this Graph? Oct 23, 2024"](img/GulfTempsPrintGraph-f24.jpg){width="100%"}
:::

::: {.column .center width="50%"}
![NYTimes "What's Going on in this Graph? Attempted Crossings at the U.S. Southern Border"](img/MigrantsBorderGraphLN-superJumbo.png){width="80%"}
:::
:::::

------------------------------------------------------------------------

## Bombardment of Data Arguments

::::: columns
::: {.column .center width="50%"}
![NYTimes "Some Colleges Have More Students From the Top 1 Percent Than the Bottom 60. Find Yours."](img/nytimes_opp_insights.png){width="100%"}
:::

::: {.column .center width="50%"}
![Kate Petrova on X, Nov 27, 2020](img/kate_petrova_candles.jpg){width="80%"}
:::
:::::

# Example: COVID Prevalence

------------------------------------------------------------------------

## Example: Visualizing COVID Prevalence {.smaller}

In May of 2020, the Georgia Department of Public Health posted the following graph:

![](img/GAcovid.jpg){width="50%" fig-align="center"}

-   At a quick first glance, what story does the Georgia Department of Public Health graph appear to be telling?

-   What is misleading about the Georgia Department of Public Health graph? How could we fix this issue?

------------------------------------------------------------------------

## Example: Visualizing COVID Prevalence {.smaller}

After public outcry, the Georgia Department of Public Health said they made a mistake and posted the following updated graph:

![](img/GAcovid2.jpg){fig-align="center" width="40%"}

-   How do your conclusions about COVID-19 cases in Georgia change when now interpreting this new graph?

------------------------------------------------------------------------

## Example: Visualizing COVID Prevalence {.smaller}

Alberto Cairo, a journalist and designer, created the second graph of the Georgia COVID-19 data:

::: {.fragment .midi}
![](img/GAcovid2.jpg){width="40%"} ![](img/GAcovid_cairo.png){width="40%"}
:::

-   A key principle of data visualization is to **"help the viewer make meaningful comparisons"**.

-   What comparisons are made easy by the lefthand graph? What about by the righthand graph?

-   From these graphs, can we get an accurate estimate of the COVID prevalence in these Georgian counties over this two week period?

------------------------------------------------------------------------

## Example: Visualizing COVID Prevalence {.smaller}

::: nonincremental
-   The [Massachusetts Water Resources Authority (MWRA) graph](https://www.mwra.com/biobot/biobotdata.htm) tracks the presence of COVID-19 in the Boston-area wastewater.
:::

```{r, echo = FALSE, fig.width= 9, fig.asp= .5}

library(tidyverse)

# Setting theme to the black and white theme

theme_set(theme_bw())

# Updating theme so that the font is size 20 or larger

theme_update(text = element_text(size = 15),

             plot.title = element_text(hjust = 0.5),

             plot.subtitle = element_text(hjust = 0.5))

# Load the data

wastewater <- read_csv("data/MWRAData20220125-data.csv")

# Clean up the column names

library(janitor)

wastewater <- clean_names(wastewater)

# Fix column types

# (Don't worry about the scary warning message)

library(lubridate)

wastewater <- mutate(wastewater,

                     sample_date = mdy(sample_date),

                     northern_copies_m_l =

                       as.numeric(northern_copies_m_l),

                     southern_copies_m_l =

                       as.numeric(southern_copies_m_l)

)

wastewater_long <- wastewater %>%

  select(sample_date, northern_copies_m_l, southern_copies_m_l) %>%

  pivot_longer(cols = c("northern_copies_m_l", "southern_copies_m_l"),

               names_to = "station",

               names_pattern = "(.*)_copies_m_l",

               values_to = "copies_m_l")

wastewater_long2 <- wastewater %>%

  select(sample_date, northern_7_day_avg, southern_7_day_avg) %>%

  pivot_longer(cols = c("northern_7_day_avg", "southern_7_day_avg"),

               names_to = "station",

               names_pattern = "(.*)_7_day_avg",

               values_to = "seven_day_avg")

wastewater_long_low <- wastewater %>%

  select(sample_date, northern_low_confidence_interval,

         southern_low_confidence_interval) %>%

  pivot_longer(cols = c("northern_low_confidence_interval",

                        "southern_low_confidence_interval"),

               names_to = "station",

               names_pattern = "(.*)_low_confidence_interval",

               values_to = "low_confidence_interval")

wastewater_long_high <- wastewater %>%

  select(sample_date, northern_high_confidence_interval,

         southern_high_confidence_interval) %>%

  pivot_longer(cols = c("northern_high_confidence_interval",

                        "southern_high_confidence_interval"),

               names_to = "station",

               names_pattern = "(.*)_high_confidence_interval",

               values_to = "high_confidence_interval")

wastewater_long <- wastewater_long %>%

  inner_join(wastewater_long2) %>%

  inner_join(wastewater_long_low)  %>%

  inner_join(wastewater_long_high)

wastewater_long %>%

  filter(sample_date >= as_date("2021-11-01"), sample_date <= as_date("2022-02-01")) %>%

ggplot(

       mapping = aes(x = sample_date,

                     y = copies_m_l,

                     color = station)) +

  geom_errorbar(mapping = aes(ymin = copies_m_l - low_confidence_interval,

                              ymax = copies_m_l + high_confidence_interval),

                alpha = 0.4) +

  geom_point(alpha = 0.3, size = 3) +

  scale_color_manual(values = c("forestgreen", "orange"))  +

  labs(y = "RNA copies/mL", x = "Date", color = "Station",

       caption = "Data from the Massachusetts Water Resources Authority",

       title = "DITP Viral RNA Signal By Date",

       subtitle = "Lines provide seven day average") +

  geom_line(mapping = aes(y = seven_day_avg), linewidth = 2) + 
  scale_x_date(date_breaks = "1 month", date_labels =  "%b %Y") #+

  #theme(legend.position = "bottom")

```

-   What are the pros of using wastewater over nasal swabs to assess COVID prevalence? What are the cons?

-   The graph also incorporates **uncertainty measures**. Quantifying uncertainty is a key component of data literacy.

------------------------------------------------------------------------

## Data Literacy In Action

:::::: columns
::: column
-   Understanding the importance of **context**.
:::

:::: column
::: fragment
{{< fa arrow-right >}} Context explains the Monday jumps in the COVID counts.
:::
::::
::::::

:::::: columns
::: column
-   How we **encode** information in a graph should be driven by our research question.
:::

:::: column
::: fragment
{{< fa arrow-right >}} You have a lot of **design choices** and these choices can help or hinder the story-telling.
:::
::::
::::::

:::::: columns
::: column
-   How the data are **collected** impacts the conclusions we can draw.
:::

:::: column
::: fragment
{{< fa arrow-right >}} Voluntary COVID test results likely don't provide good estimates of COVID prevalence.
:::
::::
::::::

:::::: columns
::: column
-   Often we are using a **sample** of data to say something about a larger group. In this case, we should measure how certain our estimates are!
:::

:::: column
::: fragment
{{< fa arrow-right >}} They sampled the wastewater and then got a range of plausible values for the RNA copies each day.
:::
::::
::::::

------------------------------------------------------------------------

## Data Analysis Process

::::: columns
::: {.column .center width="60%"}
![](img/DAW.png){width="90%"}
:::

::: {.column .center .middle width="40%"}
<br> <br> <br>

-   Need to understand how "raw" data are processed into insights.

-   What **choices** were made at each step?

-   How do those choices impact the **conclusions**?
:::
:::::

------------------------------------------------------------------------

## Data Literacy Training

-   About developing **reasoning**

    -   Not just learning definitions and formulae
    -   Not just memorizing arbitrary rules (p-value $<$ 0.05, sample size $>$ 30)

-   Requires **judgment** that takes time to develop

    -   Lots of great classes at Bucknell where students practice!

------------------------------------------------------------------------

## Dominguez Center for Data Science

-   [Seminars](https://datascience.scholar.bucknell.edu/events/)

    -   AI 101, AI 102

-   [Workshops](https://datascience.scholar.bucknell.edu/workshop/)

-   [Data Science Projects](https://datascience.scholar.bucknell.edu/projects/)

-   [Communities of Practice](https://datascience.scholar.bucknell.edu/communities-of-practice/)

    -   rugB (R Users Group at Bucknell)

------------------------------------------------------------------------

## Discussion Questions

-   How can the Center support **data literacy** at Bucknell?

-   What is data literacy to you?

-   How do you see generative AI changing or impacting data literacy?
